---
title: "Permutation-based post hoc inference for differential gene expression studies"
author: "Gilles Blanchard, Pierre Neuvial and Etienne Roquain"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    number_sections: yes
    toc: yes
  pdf_document: default
bibliography: sansSouci.bib
vignette: |
  %\VignetteIndexEntry{Permutation-based post hoc inference for differential gene expression studies}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteDepends{sansSouci.data}
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.width=8,
fig.height=6
)
```

This vignette reproduces figures from Section 9 in the book chapter: @BNR:chap. It demonstrates how the [`sansSouci`](https://github.com/pneuvial/sanssouci) package may be used to obtain post hoc confidence bounds on false positives in the case of differential gene expression analysis. After showing the output of a classical differential analysis based on False Discovery Rate control we illustrate the application of basic post-hoc bounds derived from probabilistic inequalities. 
Then, we introduce more powerful post hoc methods (introduced by @blanchard20post-hoc) that yield tighter bounds by adapting to unknown dependence by randomization. Finally we demonstrate the use of these methods on two applications of post hoc methods:

- confidence envelopes for the true or false positives
- statistical inference on volcano plots

The methods described in this vignette are described in detail in the book chapter @BNR:chap and in the paper @blanchard20post-hoc. A shiny application for volcano plots is also available from https://pneuvial.shinyapps.io/volcano-plot/.

```{r install-r-packages, results='hide', message=FALSE, eval=FALSE}
require("ggplot2") || install.packages("ggplot2")
require("sansSouci") || remotes::install_github("pneuvial/sanssouci@develop")
require("sansSouci.data") || remotes::install_github("pneuvial/sanssouci.data")
```


```{r load-r-packages, results='hide', message=FALSE}
library("ggplot2")
library("sansSouci")
```

Set the seed of the random number generator for numerical reproducibility of the results:
```{r set-seed}
set.seed(20200924)
```

# Motivation: a differential gene expression study

We focus on differential gene expression studies in cancerology. These studies aim at identifying genes whose mean expression level differs significantly between two (or more) populations, based on a sample of gene expression measurements from individuals from these populations. Specifically, we consider a data set studied in @BGH2010.

```{r load-data}
data(expr_ALL, package = "sansSouci.data")
dat <- expr_ALL
rm(expr_ALL)
```

This data set consists of gene expression measurements for  $n = `r ncol(dat)`$ patients with B-cell acute lymphoblastic leukemia (ALL) @CLGV+2005. These patients are classified into two subgoups, depending on whether or not they harbor a specific mutation called "BCR/ABL":

```{r colnames}
table(colnames(dat))
m <- nrow(dat)
```


The goal of this study is to understand the molecular differences at the gene expression level between the populations of BCR/ABL positive and negative ("NEG") patients. For each patient, we observe a vector of $m = `r m`$ gene expression values. 

The most basic question to ask is: 

> For which genes is there a difference in the mean expression level of the mutated and non-mutated population? 

This question can be addressed by performing one statistical test of no difference between means for each gene, and to define "differentially expressed" genes as those passing some significance threshold. 

Below, the Welch test for differential expression is applied to each gene. This can be done e.g. using the `sansSouci::rowWelchTests` function:

```{r row-welch-tests}
categ <- ifelse(colnames(dat) == "BCR/ABL", 1, 0) # map to 0/1
dex <- data.frame(rowWelchTests(dat, categ))
pval <- dex[["p.value"]]
```

We plot a histogram of the corresponding $p$-values:

```{r hist}
hist(pval, probability = TRUE, breaks = 20,
     xlab = "p-value", main = "p-value distributon")
```

As expected, the distribution presents a large number of small $p$-values (which include signals, i.e. differentially expressed genes) mixed with uniformly distributed $p$-values (corresponding to non-differentially expressed genes). 

## Multiple testing correction: False Discovery Rate control 

The state of the art approach to large-scale multiple testing is to control the False Discovery Rate (FDR), which is the expected proportion of wrongly selected genes (false positives) among all selected genes @benjamini95controlling. The most widely used method to control this risk is the Benjamini-Hochberg (BH) procedure, which has been shown to control the FDR when the hypotheses corresponding to the non-differentially expressed genes are independent @benjamini95controlling or satisfy a specific type of positive dependence called Positive Regression Dependence on the Subset (PRDS) $\mathcal{H}_0$ of truly non-differentially expressed genes @benjamini01control.

```{r bh}
q <- 0.05
adjp.BH <- p.adjust(pval, method = "BH")
dex$adjp <- adjp.BH
nBH <- sum(adjp.BH <= q)
nBH
```

The application of the BH procedure at level $q = `r q`$ is illustrated in the figures below (all genes are displayed in the first one, second one is a zoom on the top genes):

```{r bh-plot}
my_col <- "#FF000080"
dexo <- dex[order(pval), ]  ## order genes by increasing p-values
dexo[["gene_order"]] <- 1:nrow(dex)

bh_plot <- ggplot(dexo, aes(x = gene_order, y = p.value)) + 
  geom_line() +
  xlab("Number of top genes") + ylab("Ordered p-value") +
  geom_abline(slope = 1/m, intercept = 0, linetype = 2, size = 1) +
  geom_abline(slope = q/m, color = my_col, size = 2) +
  # geom_segment(aes(x = nBH, y = 0, yend = q*nBH/m, xend = nBH), linetype = "dotted") +
  # geom_segment(aes(x = 0, y = q*nBH/m, xend = nBH, yend = q*nBH/m), linetype = "dotted") +
  geom_abline(slope = 0, intercept = q, linetype = "dotted", color = my_col, size = 2) +
  theme_bw() +
  theme(axis.text = element_text(size = 14), 
        axis.title = element_text(size = 18))  
#geom_text(x = 0, y = q, label = expression(alpha), color = my_col)

bh_plot
```

```{r bh-plot-zoom}
xmax <- nBH*2.5
ymax <- dexo$p.value[xmax]
bh_plot + 
  xlim(1, xmax) + ylim(0, ymax) +
  geom_segment(aes(x = nBH, y = 0, yend = q*nBH/m, xend = nBH), linetype = "dotted") +
  geom_segment(aes(x = 1, y = q*nBH/m, xend = nBH, yend = q*nBH/m), linetype = "dotted", col = 1)
```

## Basic posthoc bounds

Post hoc inference makes it possible to build confidence statements on the number of true/false positives within any set $S$ of genes: $S$ may be selected after seing the data (e.g., $S$ may be the set of rejections by the BH prcedure), and multiple choices of $S$ are allowed. Post hoc inference has been popularized by @GS2011. 


```{r basic-bounds-setup}
alpha <- 0.1
pvalo <- dexo$p.value
```

### $k_0$-Bonferroni bound

For a fixed $k_0$, the generalized Bonferroni procedure consisting in rejecting the hypotheses in $R_{k_0} = \{i: p_i \leq \alpha k_0/m\}$ controls the $k_0$-Family-Wise Error Rate: it ensures that with probability larger than $1-\alpha$, the number of false positives in $R_{k_0}$ is not larger than $k_0-1$. As noted in  @BNR:chap, this leads to the post hoc bound: 

$$V(S)=\sum_{i\in S} 1_{\{p_i \geq \alpha k_0 /|S|\}} + k_0-1$$

As an application we calculate the bound associated to $k_0=100$ for $\alpha = `r alpha`$:

```{r k0-bonf}
k0 <- 100
S <- 1:nBH
FP_k0 <- sum(pvalo[S] >= alpha*k0/m) + k0 - 1
FP_k0/nBH
```

This implies that with probability larger than `r 1-alpha` the false discovery proportion among the genes selected by the BH procedure at level $q= `r q`$ is upper bounded by `r ceiling(FP_k0/nBH*100)/100`.

### Simes bound

A more refined post hoc bound has been proposed by @GS2011 under the PRDS assumption. In the framework of @BNR:chap this bound is a direct consequence of the @simes86improved inequality. It can be applied to the `r nBH` rejections of the BH procedure as follows:

```{r}
#posthocBySimes(pvalo, 1:nBH, alpha = alpha)
thr_Simes <- SimesThresholdFamily(m)(alpha)
FP_Simes <- maxFP(pvalo[1:nBH], thr_Simes)
FP_Simes
FP_Simes/nBH
```

The Simes bound implies that with probability larger than `r 1-alpha`, the false discovery proportion among the genes selected by the BH procedure at level $q= `r q`$ is upper bounded by `r ceiling(FP_Simes/nBH*100)/100`. The Simes bound is sharper than the $k_0$-Bonferroni bound because it is obtained from a *joint* control of all $k$-FWER for all $k=1, \dots, m$.


```{r k0-bonf-fam, eval=FALSE, echo=FALSE}
# Sanity check (one-element reference family)
thr0 <- rep(0, m)
thr0[k0:m] <- thr_Simes[k0]
FP_k0 + minTP(pvalo[1:nBH], thr0) == nBH
```


# Tighter confidence bounds by adaptation to unknown dependence 

As discussed in @blanchard20post-hoc, the above-described bound has two major limitations, being a consequence of the Simes inequality:

- It is known to be valid only under certain positive dependence assumptions (PRDS) on the joint $p$-value distribution. Although the PRDS assumption is generally accepted in the case of differential expression studies (which justifies the application of the BH procedure itself), it has not been formally proved to hold in this case.

- It is not *adaptive* to the specific type of dependence at hand for a particular data set.

To bypass these limitations, @blanchard20post-hoc have proposed a randomization-based procedure known as $\lambda$-calibration, which yields tighter bounds that are adapted to the dependency observed in the data set at hand^[A related approach has been proposed by @HSG2019, but no implementation is currently available for this approach.]. In the case of two-sample tests, this calibration can be achieved by permutation of class labels:

```{r calibration, cache=TRUE}
B <- 1000
cal <- calibrateJER(X = dat, categ, B = B, alpha = alpha, refFamily = "Simes")
```


An alternative to the Simes/Linear reference family is the Beta reference family:

```{r calibration-beta, cache=TRUE}
K <- 50
cal_beta <- calibrateJER(X = dat, categ, B = B, alpha = alpha, refFamily = "Beta", K = K)
```

```{r calibration-BH}
FP_SimesCal <- maxFP(pvalo[1:nBH], cal$thr)
FP_SimesCal/nBH
FP_BetaCal <- maxFP(pvalo[1:nBH], cal_beta$thr)
FP_BetaCal/nBH
```

The FDP bound obtained by these bounds is much tighter than the $k_0$-Bonferroni and Simes bounds:

```{r tighter-bounds}
bounds <- c("k0-Bonferroni" = FP_k0, 
         "Simes" = FP_Simes,
         "Linear" = FP_SimesCal,
         "Beta" = FP_BetaCal)
names(bounds)[4] <- sprintf("Beta (K=%s)", K)

tab <- data.frame("Method" = names(bounds), 
                  "Lower bound on True Positives" = nBH - bounds, 
                  "Upper bound on False Discovery Proportion" = ceiling(bounds/nBH*100)/100,
                  check.names = FALSE, row.names = NULL)
knitr::kable(tab)
```

In the next two sections we illustrate the use of these improved bounds in order to build

- confidence envelopes for the true or false positives
- confidence statements for volcano plots

# Confidence envelopes on "top-$k$" lists

In the absence of prior information on genes, a natural idea is to rank them by decreasing statistical significance, and a natural question to ask is: 

> Can we provide a lower confidence envelope on the number (or proportion) of truly differentially expressed genes among the most significant genes?

We illustrate the use of post-hoc methods to provide this type of information. More specifcally, we build confidence statements on the number of true/false positives within the top $k$ most significant genes in a differential gene expression study, where $k$ may be defined by the user after seing the data, and multiple choices of $k$ are allowed. 

The method of @GS2011 makes it possible to calculate a confidence envelope on the number of true positives among the most significant genes. This is obtained as follows via the `sansSouci` package:

```{r plot-conf-envelope}
xmax <- 300
ce_Simes <- confidenceEnvelope(dex$p.value, refFamily = 'Simes', param = alpha)
p <- plotConfidenceEnvelope(ce_Simes, xmax = xmax)
p + geom_vline(xintercept = nBH, color = "gray", linetype = "dotted", size = 1.5) +
  geom_line(size=1.5)
```

The confidence envelopes obtained by calibration of the Simes and Beta families can be compared graphically to the Simes envelope:

```{r, conf-env-plot}
conf_envs <- list("Simes" = ce_Simes,
                  "Linear" = cal$conf_env,
                  "Beta" = cal_beta$conf_env)
names(conf_envs)[3] <- sprintf("Beta (K=%s)", K)
cols <- RColorBrewer::brewer.pal(length(conf_envs), "Dark2")
p <- plotConfidenceEnvelope(conf_envs, xmax = 300, cols = cols)
p + geom_vline(xintercept = nBH, color = "gray", linetype = "dotted", size = 1.5) +
  geom_line(size = 1.5)
```

Both calibrated envelopes outperform the Simes envelope in this example. 

# Volcano plots

For an interactive volcano plot, see the [volcano plot shiny application](https://pneuvial.shinyapps.io/volcano-plot/).

```{r volcano-setup}
thrs <- list("Simes" = thr_Simes,
             "Lines" = cal$thr,
             "Beta"= cal_beta$thr)
names(thrs) <- names(conf_envs)
q <- 0.05
r <-  0.3
```

Let us assume that we are interested in genes selected by the BH procedure at level $q = `r q`$ and whose fold change is larger than $r = `r r`$ in absolute value.  The "fold change" is defined as the difference between the expression means of the two groups compared; it is an estimate of the effect size of a gene. This double selection corresponds to two sets of genes, with positive/negative fold change, which can be represented in the following plot:


```{r volcano-plot-Simes}
ylim <- c(0, 6)
thr <- thrs[["Simes"]]
vo <- volcanoPlot(dat, categ = categ, thr = thr, q = q, r = r, ylim = ylim)
```

This type of plot is called a "volcano plot" @CC2003. Post hoc inference makes it possible to obtain statistical guarantees on selections such as the ones represented in the above figure. 

The substantial gain in power offered by the above-described calibration is illustrated as follows for the Simes reference family:

```{r volcano-plot-Simes-calibrated}
thr <- thrs[["Linear"]]
volcanoPlot(dat, categ = categ, thr = thr, q = q, r = r, ylim = ylim)
```

and for the Beta reference family.

```{r volcano-plot-Beta-calibrated}
thr <- thrs[[sprintf("Beta (K=%s)", K)]]
volcanoPlot(dat, categ = categ, thr = thr, q = q, r = r, ylim = ylim)
```

The comparison between these bounds may be summarized by the following Table:

```{r compare-volcano-bounds}
all_bounds <- function(pvals, thrs) {
  c("|S|" = length(pvals), sapply(thrs, function(thr) minTP(pvals, thr)))
}
pval_pos <- subset(dexo, meanDiff >= r & adjp <= q)$p.value
pval_neg <- subset(dexo, meanDiff <= -r & adjp <= q)$p.value
pval_all <- c(pval_pos, pval_neg)
tab <- rbind(all_bounds(pval_pos, thrs), 
             all_bounds(pval_neg, thrs),
             all_bounds(pval_all, thrs))
tab <- cbind(c("BH-adjusted p.value < q and fold change > r",
               "BH-adjusted p.value < q and fold change < -r",
               "BH-adjusted p.value < q and |fold change| > r"), 
             tab)
cap <- "Post hoc bounds on true positives in user-defined gene selections"
knitr::kable(tab, caption = cap)
```

# Session information

```{r session-info}
sessionInfo()
```

# Reproducibility

To re-build this vignette from its source, use: 

```{r reproducibility, eval = FALSE}
rmarkdown::render("post-hoc_differential-expression.Rmd", output_format = "pdf_document")
# To keep intermediate files, add option 'clean = FALSE'
rmarkdown::render("post-hoc_differential-expression.Rmd", output_format = "html_document")
```

# References


